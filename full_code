"""
NBA Player Stats Analysis using PySpark and Scikit-learn

- Dimensionality Reduction (PCA)
- Clustering (KMeans, BisectingKMeans)
- Classification (KNN, SVM)
- Regression (Predicting 3P%)

Author: Finley Michael Mbella
"""

# --- Import Libraries ---
from pyspark.sql import SparkSession
from pyspark.sql.functions import when
from pyspark.ml.feature import VectorAssembler, PCA
from pyspark.ml.clustering import KMeans, BisectingKMeans
from pyspark.ml.evaluation import ClusteringEvaluator, RegressionEvaluator, BinaryClassificationEvaluator
from pyspark.ml.regression import LinearRegression
from pyspark.ml.classification import LinearSVC

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Start Spark Session 
spark = SparkSession.builder.appName("NBA Analysis").getOrCreate()

# Load & prep data 
df = spark.read.csv("/content/NBASeason.csv", header=True, inferSchema=True).dropna()

# Section 1: PCA + KMeans Clustering
features_pca = ["Age", "G", "GS", "MP", "FG", "FGA", "FG%", "3P", "3PA", "3P%"]
assembler_pca = VectorAssembler(inputCols=features_pca, outputCol="features")
df_pca = assembler_pca.transform(df)

# Apply PCA
pca = PCA(k=2, inputCol="features", outputCol="pca_features")
pca_model = pca.fit(df_pca)
df_pca = pca_model.transform(df_pca)

print("Explained Variance Ratio:", pca_model.explainedVariance.toArray())

# KMeans Clustering
kmeans = KMeans(k=2, seed=42, featuresCol="pca_features", predictionCol="prediction")
kmeans_model = kmeans.fit(df_pca)
pred_kmeans = kmeans_model.transform(df_pca)

evaluator = ClusteringEvaluator(featuresCol="pca_features", predictionCol="prediction")
print("Silhouette Score (KMeans):", evaluator.evaluate(pred_kmeans))
print("Cluster Centres:", kmeans_model.clusterCenters())

# Section 2: KNN Classification
# Convert to Pandas
pandas_df = df_pca.toPandas()
X = np.array(pandas_df["features"].tolist())
y = pandas_df["Pos"]

# Encode categorical labels
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Split & standardise
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

print(f"KNN Accuracy: {accuracy_score(y_test, y_pred):.2f}")
print("KNN Classification Report:")
print(classification_report(y_test, y_pred, target_names=le.classes_))

# Section 3: Linear Regression
features_lr = ["FT", "Age", "3PA", "G", "GS", "MP"]
assembler_lr = VectorAssembler(inputCols=features_lr, outputCol="features")
df_lr = assembler_lr.transform(df).select("features", "3P%")

# Train/Test Split
train_lr, test_lr = df_lr.randomSplit([0.7, 0.3], seed=42)

lr = LinearRegression(featuresCol="features", labelCol="3P%")
lr_model = lr.fit(train_lr)
predictions_lr = lr_model.transform(test_lr)

evaluator_lr = RegressionEvaluator(labelCol="3P%", predictionCol="prediction", metricName="rmse")
rmse = evaluator_lr.evaluate(predictions_lr)

print("Linear Regression RMSE:", rmse)
print("Coefficients:", lr_model.coefficients)
print("Intercept:", lr_model.intercept)

# Visualise Actual vs Predicted
actual = np.array(predictions_lr.select("3P%").rdd.flatMap(lambda x: x).collect())
predicted = np.array(predictions_lr.select("prediction").rdd.flatMap(lambda x: x).collect())

plt.figure(figsize=(8, 6))
plt.scatter(actual, predicted, alpha=0.6)
plt.plot([0, max(actual)], [0, max(actual)], linestyle='--', color='red')
plt.xlabel("Actual 3P%")
plt.ylabel("Predicted 3P%")
plt.title("Actual vs. Predicted 3P% (Linear Regression)")
plt.grid(True)
plt.show()

# Section 4: Bisecting KMeans
features_bk = ["Age", "G", "GS", "MP", "FG", "FGA", "FG%", "3P", "3PA"]
assembler_bk = VectorAssembler(inputCols=features_bk, outputCol="features")
df_bk = assembler_bk.transform(df.limit(100)).select("features")

bkmeans = BisectingKMeans(featuresCol="features", predictionCol="prediction", k=2)
bk_model = bkmeans.fit(df_bk)
pred_bk = bk_model.transform(df_bk)

print("Silhouette Score (BisectingKMeans):", evaluator.evaluate(pred_bk))

# Section 5: SVM Classification
features_svm = ["2P", "2PA", "2P%", "FT", "FTA", "FT%"]
assembler_svm = VectorAssembler(inputCols=features_svm, outputCol="features")
df_svm = assembler_svm.transform(df)

# Binary label: high 3P shooters
df_svm = df_svm.withColumn("label", when(df_svm["3P"] > 1.4, 1).otherwise(0))
data_svm = df_svm.select("features", "label")

train_svm, test_svm = data_svm.randomSplit([0.8, 0.2], seed=42)
svm = LinearSVC(featuresCol="features", labelCol="label")
svm_model = svm.fit(train_svm)

predictions_svm = svm_model.transform(test_svm)

evaluator_svm = BinaryClassificationEvaluator(labelCol="label")
print("SVM AUC:", evaluator_svm.evaluate(predictions_svm))

# Confusion Matrix
y_true = predictions_svm.select("label").rdd.flatMap(lambda x: x).collect()
y_pred = predictions_svm.select("prediction").rdd.flatMap(lambda x: x).collect()
cm = confusion_matrix(y_true, y_pred)

# Plot Confusion Matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Low", "High"], yticklabels=["Low", "High"])
plt.title("SVM Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Done 
spark.stop()